{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "<h2>Project 5: Bias Variance Trade-Off</h2>\n",
    "\n",
    "<!--announcements-->\n",
    "<blockquote>\n",
    "    <center>\n",
    "    <a href=\"http://blogs.worldbank.org/publicsphere/files/publicsphere/biased_processing.jpg\"><img src=\"https://raw.githubusercontent.com/aevanchen/machine_learning_miniprojects/5363ecd7985c9a8de20f9d1b827512280a14ed7e/Bias%20Variance%20Tradeoff/bias.jpg\" width=\"600px\" /></a>\n",
    "    </center>\n",
    "      <p><cite><center>\"All of us show bias when it comes to what information we take in.<br>We typically focus on anything that agrees with the outcome we want.\"<br>\n",
    "<b>--Noreena Hertz</b>\n",
    "      </center></cite></p>\n",
    "</blockquote>\n",
    "<h3>Introduction</h3>\n",
    "\n",
    "<p>\n",
    "Recall that the squared error can be decomposed into <em>bias</em>, <em>variance</em> and <em>noise</em>: \n",
    "</p>\n",
    "$$\n",
    "    \\underbrace{\\mathbb{E}[(h_D(x) - y)^2]}_\\mathrm{Error} = \\underbrace{\\mathbb{E}[(h_D(x)-\\bar{h}(x))^2]}_\\mathrm{Variance} + \\underbrace{\\mathbb{E}[(\\bar{h}(x)-\\bar{y}(x))^2]}_\\mathrm{Bias} + \\underbrace{\\mathbb{E}[(\\bar{y}(x)-y(x))^2]}_\\mathrm{Noise}\\nonumber\n",
    "$$\n",
    "We will now create a data set for which we can approximately compute this decomposition. \n",
    "The function <em><strong>`toydata`</strong></em> generates a binary data set with class $1$ and $2$. Both are sampled from Gaussian distributions:\n",
    "$$\n",
    "p(\\vec x|y=1)\\sim {\\mathcal{N}}(0,{I}) \\textrm { and } p(\\vec x|y=2)\\sim {\\mathcal{N}}(\\mu_2,{I}),\n",
    "$$\n",
    "\n",
    "where $\\mu_2=[2;2]^\\top$ (the global variable <em>OFFSET</em> $\\!=\\!2$ regulates these values: $\\mu_2=[$<em>OFFSET</em> $;$ <em>OFFSET</em>$]^\\top$).\n",
    "\n",
    "<h3>Computing noise, bias and variance</h3>\n",
    "<p>\n",
    "You will need to edit four functions:  <em><strong>`computeybar`</strong></em>,  <em><strong>`computehbar`</strong></em>, and <em><strong>`computevariance`</strong></em>. First take a look at <strong>`biasvariancedemo`</strong> and make sure you understand where each function should be called and how they contribute to the Bias/Variance/Noise decomposition. <br/><br/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l2distance Helper Function: l2distance is a helper function used in our implementation of the ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "import numpy as np\n",
    "from numpy.matlib import repmat\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`l2distance` Helper Function**: `l2distance` is a helper function used in our implementation of the ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2distance(X, Z=None):\n",
    "    \"\"\"\n",
    "    function D=l2distance(X,Z)\n",
    "\n",
    "    Computes the Euclidean distance matrix.\n",
    "    Syntax:\n",
    "    D=l2distance(X,Z)\n",
    "    Input:\n",
    "    X: dxn data matrix with n vectors (columns) of dimensionality d\n",
    "    Z: dxm data matrix with m vectors (columns) of dimensionality d\n",
    "\n",
    "    Output:\n",
    "    Matrix D of size nxm\n",
    "    D(i,j) is the Euclidean distance of X(:,i) and Z(:,j)\n",
    "\n",
    "    call with only one input:\n",
    "    l2distance(X)=l2distance(X,X)\n",
    "    \"\"\"\n",
    "    if Z is None:\n",
    "        n, d = X.shape\n",
    "        s1 = np.sum(np.power(X, 2), axis=1).reshape(-1,1)\n",
    "        D1 = -2 * np.dot(X, X.T) + repmat(s1, 1, n)\n",
    "        D = D1 + repmat(s1.T, n, 1)\n",
    "        np.fill_diagonal(D, 0)\n",
    "        D = np.sqrt(np.maximum(D, 0))\n",
    "    else:\n",
    "        n, d = X.shape\n",
    "        m, _ = Z.shape\n",
    "        s1 = np.sum(np.power(X, 2), axis=1).reshape(-1,1)\n",
    "        s2 = np.sum(np.power(Z, 2), axis=1).reshape(1,-1)\n",
    "        D1 = -2 * np.dot(X, Z.T) + repmat(s1, 1, m)\n",
    "        D = D1 + repmat(s2, n, 1)\n",
    "        D = np.sqrt(np.maximum(D, 0))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`toydata` Helper Function**: `toydata` is a helper function used to generate the the binary data with n/2 values in class 1 and n/2 values in class 2. With class 1 being the label for data drawn from a normal distribution having mean 0 and sigma 1. And clss 2 being the label for data drawn from a normal distribution with mean OFFSET and sigma 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def toydata(OFFSET,N):\n",
    "    \"\"\"\n",
    "    function [x,y]=toydata(OFFSET,N)\n",
    "    \n",
    "    This function constructs a binary data set. \n",
    "    Each class is distributed by a standard Gaussian distribution.\n",
    "    INPUT: \n",
    "    OFFSET:  Class 1 has mean 0,  Class 2 has mean 0+OFFSET (in each dimension). \n",
    "    N: The function returns N data points ceil(N/2) are of class 2, the rest\n",
    "    of class 1\n",
    "    \"\"\"\n",
    "    \n",
    "    NHALF = int(np.ceil(N/2))\n",
    "    x = np.random.randn(N, 2)\n",
    "    x[NHALF:, :] += OFFSET  \n",
    "    \n",
    "    y = np.ones(N)\n",
    "    y[NHALF:] *= 2\n",
    "    \n",
    "    jj = np.random.permutation(N)\n",
    "    \n",
    "    print (x[jj])\n",
    "    return x[jj, :], y[jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.59456655  1.60216872]\n",
      " [-1.22902249 -1.83130043]\n",
      " [ 1.31112407 -0.67543397]\n",
      " [-0.38395877 -0.99928839]\n",
      " [ 0.41572693  4.40436763]\n",
      " [ 4.08393626  2.58557171]\n",
      " [ 2.29415367  3.65758881]\n",
      " [ 4.40490135  2.55289446]\n",
      " [-1.47787405 -0.41659778]\n",
      " [-1.80059895 -0.09314875]\n",
      " [ 0.30200512 -0.01705625]\n",
      " [-1.5230949   0.09228622]\n",
      " [ 3.14126345  0.90269356]\n",
      " [ 3.69582676  2.62390319]\n",
      " [ 3.18165667  2.58298073]\n",
      " [-0.63117444 -0.20332523]\n",
      " [ 4.09329023  2.21491907]\n",
      " [ 2.49524515  3.66286313]\n",
      " [-1.85552924 -0.07195628]\n",
      " [ 0.15573078  0.05045767]\n",
      " [ 3.00901001  1.51319057]\n",
      " [ 1.17892757  3.00247259]\n",
      " [-0.45537785 -0.68127373]\n",
      " [-1.27035741 -1.64217608]\n",
      " [ 3.58965533  1.92721359]\n",
      " [ 4.28222641  2.05357112]\n",
      " [ 2.52781481  3.7165535 ]\n",
      " [ 0.4344148   0.84335454]\n",
      " [ 1.316867   -0.58464943]\n",
      " [ 1.26941594  3.53871078]\n",
      " [-1.29780532  0.71771997]\n",
      " [ 2.68226594  2.98642926]\n",
      " [ 0.24749674  1.31253148]\n",
      " [-0.6970849   0.66995494]\n",
      " [ 3.36569503  2.22102171]\n",
      " [ 2.83071056  2.40802905]\n",
      " [-0.33685259  0.21863593]\n",
      " [ 4.76523464  3.47372425]\n",
      " [ 2.45728412  2.36227788]\n",
      " [ 0.16046752  0.72470563]\n",
      " [ 0.98072218  0.86089191]\n",
      " [ 3.65279175  2.98140308]\n",
      " [ 2.9587105   2.92584851]\n",
      " [-0.01633991 -1.81216973]\n",
      " [-1.46537171  0.86189201]\n",
      " [ 3.60313832  2.22425106]\n",
      " [ 3.1284998   2.25221316]\n",
      " [ 1.45251837  0.18406681]\n",
      " [ 0.58904281  0.45275392]\n",
      " [ 0.79283386  0.25963521]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 4.59456655,  1.60216872],\n",
       "        [-1.22902249, -1.83130043],\n",
       "        [ 1.31112407, -0.67543397],\n",
       "        [-0.38395877, -0.99928839],\n",
       "        [ 0.41572693,  4.40436763],\n",
       "        [ 4.08393626,  2.58557171],\n",
       "        [ 2.29415367,  3.65758881],\n",
       "        [ 4.40490135,  2.55289446],\n",
       "        [-1.47787405, -0.41659778],\n",
       "        [-1.80059895, -0.09314875],\n",
       "        [ 0.30200512, -0.01705625],\n",
       "        [-1.5230949 ,  0.09228622],\n",
       "        [ 3.14126345,  0.90269356],\n",
       "        [ 3.69582676,  2.62390319],\n",
       "        [ 3.18165667,  2.58298073],\n",
       "        [-0.63117444, -0.20332523],\n",
       "        [ 4.09329023,  2.21491907],\n",
       "        [ 2.49524515,  3.66286313],\n",
       "        [-1.85552924, -0.07195628],\n",
       "        [ 0.15573078,  0.05045767],\n",
       "        [ 3.00901001,  1.51319057],\n",
       "        [ 1.17892757,  3.00247259],\n",
       "        [-0.45537785, -0.68127373],\n",
       "        [-1.27035741, -1.64217608],\n",
       "        [ 3.58965533,  1.92721359],\n",
       "        [ 4.28222641,  2.05357112],\n",
       "        [ 2.52781481,  3.7165535 ],\n",
       "        [ 0.4344148 ,  0.84335454],\n",
       "        [ 1.316867  , -0.58464943],\n",
       "        [ 1.26941594,  3.53871078],\n",
       "        [-1.29780532,  0.71771997],\n",
       "        [ 2.68226594,  2.98642926],\n",
       "        [ 0.24749674,  1.31253148],\n",
       "        [-0.6970849 ,  0.66995494],\n",
       "        [ 3.36569503,  2.22102171],\n",
       "        [ 2.83071056,  2.40802905],\n",
       "        [-0.33685259,  0.21863593],\n",
       "        [ 4.76523464,  3.47372425],\n",
       "        [ 2.45728412,  2.36227788],\n",
       "        [ 0.16046752,  0.72470563],\n",
       "        [ 0.98072218,  0.86089191],\n",
       "        [ 3.65279175,  2.98140308],\n",
       "        [ 2.9587105 ,  2.92584851],\n",
       "        [-0.01633991, -1.81216973],\n",
       "        [-1.46537171,  0.86189201],\n",
       "        [ 3.60313832,  2.22425106],\n",
       "        [ 3.1284998 ,  2.25221316],\n",
       "        [ 1.45251837,  0.18406681],\n",
       "        [ 0.58904281,  0.45275392],\n",
       "        [ 0.79283386,  0.25963521]]),\n",
       " array([2., 1., 1., 1., 2., 2., 2., 2., 1., 1., 1., 1., 2., 2., 2., 1., 2.,\n",
       "        2., 1., 1., 2., 2., 1., 1., 2., 2., 2., 1., 1., 2., 1., 2., 1., 1.,\n",
       "        2., 2., 1., 2., 2., 1., 1., 2., 2., 1., 1., 2., 2., 1., 1., 1.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "toydata(3,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <p> -->\n",
    "(a) <strong>Noise:</strong> First we focus on the noise. For this, you need to compute $\\bar y(\\vec x)$ in  <em><strong>`computeybar`</strong></em>. You can compute the probability $p(\\vec x|y)$ with the equations $p(\\vec x|y=1)\\sim {\\mathcal{N}}(0,{I}) \\textrm { and } p(\\vec x|y=2)\\sim {\\mathcal{N}}(\\mu_2,{I})$. Then use Bayes rule to compute $p(y|\\vec x)$. <br/><br/>\n",
    "<strong>Note:</strong> You may want to use the function <em>`normpdf`</em>, which is defined for  you in <em><strong>`computeybar`</strong></em>.\n",
    "<br/><br/>\n",
    "<!-- </p> -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeybar(xTe, OFFSET):\n",
    "    \"\"\"\n",
    "    function [ybar]=computeybar(xTe, OFFSET);\n",
    "\n",
    "    computes the expected label 'ybar' for a set of inputs x\n",
    "    generated from two standard Normal distributions (one offset by OFFSET in\n",
    "    both dimensions.)\n",
    "\n",
    "    INPUT:\n",
    "    xTe : nx2 array of n vectors with 2 dimensions\n",
    "    OFFSET    : The OFFSET passed into the toyData function. The difference in the\n",
    "                mu of labels class1 and class2 for toyData.\n",
    "\n",
    "    OUTPUT:\n",
    "    ybar : a nx1 vector of the expected labels for vectors xTe\n",
    "    \"\"\"\n",
    "    n,temp = xTe.shape\n",
    "    ybar = np.zeros(n)\n",
    "    \n",
    "    # Feel free to use the following function to compute p(x|y), or not\n",
    "    # normal distribution is default mu = 0, sigma = 1.\n",
    "    normpdf = lambda x, mu, sigma: np.exp(-0.5 * np.power((x - mu) / sigma, 2)) / (np.sqrt(2 * np.pi) * sigma)\n",
    "    \n",
    "    ## fill in code here\n",
    "    #raise NotImplementedError('Your code goes here!')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
