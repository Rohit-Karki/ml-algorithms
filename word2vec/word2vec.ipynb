{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    stopwords = f.read().replace('\\n', ' ').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today we will be learning about the fundamentals of data science and statistics. Data Science and statistics are hot and growing fields with alternative names of machine learning, artificial intelligence, big data, etc. I'm really excited to talk to you about data science and statistics because data science and statistics have long been a passions of mine. I didn't used to be very good at data science and statistics but after studying data science and statistics for a long time, I got better and better at it until I became a data science and statistics expert. I'm really excited to talk to you about data science and statistics, thanks for listening to me talk about data science and statistics.\n",
      "['today', 'we', 'will', 'be', 'learning', 'about', 'the', 'fundamentals', 'of', 'data', 'science', 'and', 'statistics', 'data', 'science', 'and', 'statistics', 'are', 'hot', 'and', 'growing', 'fields', 'with', 'alternative', 'names', 'of', 'machine', 'learning', 'artificial', 'intelligence', 'big', 'data', 'etc', 'im', 'really', 'excited', 'to', 'talk', 'to', 'you', 'about', 'data', 'science', 'and', 'statistics', 'because', 'data', 'science', 'and', 'statistics', 'have', 'long', 'been', 'a', 'passions', 'of', 'mine', 'i', 'didnt', 'used', 'to', 'be', 'very', 'good', 'at', 'data', 'science', 'and', 'statistics', 'but', 'after', 'studying', 'data', 'science', 'and', 'statistics', 'for', 'a', 'long', 'time', 'i', 'got', 'better', 'and', 'better', 'at', 'it', 'until', 'i', 'became', 'a', 'data', 'science', 'and', 'statistics', 'expert', 'im', 'really', 'excited', 'to', 'talk', 'to', 'you', 'about', 'data', 'science', 'and', 'statistics', 'thanks', 'for', 'listening', 'to', 'me', 'talk', 'about', 'data', 'science', 'and', 'statistics']\n"
     ]
    }
   ],
   "source": [
    "with open('training_text.txt', encoding='utf-8') as f:\n",
    "    text = f.read().replace('\\n', '')\n",
    "    print(text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = ''.join([t for t in text if t not in list('0123456789')])\n",
    "    text = text.replace('”', '').replace(\n",
    "        '“', '').replace('’', '').lower().split()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare our Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3\n",
    "NUM_NEGATIVE_SAMPLES = 3\n",
    "\n",
    "data = []\n",
    "# iterate over all words\n",
    "for idx, center_word in enumerate(text[WINDOW_SIZE-1:-WINDOW_SIZE]):\n",
    "\n",
    "    # iterate over the context words around the center word\n",
    "    context_words = [context_word for context_word in text[idx:idx + 2*WINDOW_SIZE-1] if context_word != center_word]\n",
    "    for context_word in context_words:\n",
    "\n",
    "        # get words NOT in the current context as negative examples\n",
    "        data.append([center_word, context_word, 1])\n",
    "        negative_samples = np.random.choice(\n",
    "            [w for w in text[WINDOW_SIZE-1:-WINDOW_SIZE] if w != center_word and w not in context_words], NUM_NEGATIVE_SAMPLES)\n",
    "\n",
    "        for negative_samp in negative_samples:\n",
    "\n",
    "            # add a training row\n",
    "            data.append([center_word, negative_samp, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['center_word', 'context_word', 'label'], data=data)\n",
    "words = np.intersect1d(df.context_word, df.center_word)\n",
    "df = df[(df.center_word.isin(words)) & (\n",
    "    df.context_word.isin(words))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(v,scale=1):\n",
    "    return 1/(1+np.exp(-scale*v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateEmbedding(df, main_embeddings, context_embeddings, learning_rate, debug=False):\n",
    "    # get differences between main_embeddings and context_embeddings\n",
    "    main_embeddings_center = main_embeddings.loc(df.center_word).values\n",
    "    context_embeddings_context = context_embeddings.loc(df.context_word).values\n",
    "    diffs = context_embeddings_context - main_embeddings_center\n",
    "\n",
    "    # get the similarity, scores and the errors between main_embeddings_center and context_embeddings_center\n",
    "    dot_prods = np.sum(main_embeddings_center * context_embeddings_context,axis = 1)\n",
    "    scores = sigmoid(dot_prods )\n",
    "    errors = (df.label - scores).values.reshape(-1,1)\n",
    "    \n",
    "    # Calculate the updates\n",
    "    updates = diffs*errors*learning_rate\n",
    "    updates_df = pd.DataFrame(data = updates)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
